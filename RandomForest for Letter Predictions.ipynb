{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the necessary libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading data into pandas dataframe\n",
    "data=pd.read_csv(\"letter.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>f10</th>\n",
       "      <th>...</th>\n",
       "      <th>f609</th>\n",
       "      <th>f610</th>\n",
       "      <th>f611</th>\n",
       "      <th>f612</th>\n",
       "      <th>f613</th>\n",
       "      <th>f614</th>\n",
       "      <th>f615</th>\n",
       "      <th>f616</th>\n",
       "      <th>f617</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.4394</td>\n",
       "      <td>-0.0930</td>\n",
       "      <td>0.1718</td>\n",
       "      <td>0.4620</td>\n",
       "      <td>0.6226</td>\n",
       "      <td>0.4704</td>\n",
       "      <td>0.3578</td>\n",
       "      <td>0.0478</td>\n",
       "      <td>-0.1184</td>\n",
       "      <td>-0.2310</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4102</td>\n",
       "      <td>0.2052</td>\n",
       "      <td>0.3846</td>\n",
       "      <td>0.3590</td>\n",
       "      <td>0.5898</td>\n",
       "      <td>0.3334</td>\n",
       "      <td>0.6410</td>\n",
       "      <td>0.5898</td>\n",
       "      <td>-0.4872</td>\n",
       "      <td>'1'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.4348</td>\n",
       "      <td>-0.1198</td>\n",
       "      <td>0.2474</td>\n",
       "      <td>0.4036</td>\n",
       "      <td>0.5026</td>\n",
       "      <td>0.6328</td>\n",
       "      <td>0.4948</td>\n",
       "      <td>0.0338</td>\n",
       "      <td>-0.0520</td>\n",
       "      <td>-0.1302</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2954</td>\n",
       "      <td>0.2046</td>\n",
       "      <td>0.4772</td>\n",
       "      <td>0.0454</td>\n",
       "      <td>0.2046</td>\n",
       "      <td>0.4318</td>\n",
       "      <td>0.4546</td>\n",
       "      <td>-0.0910</td>\n",
       "      <td>'1'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.2330</td>\n",
       "      <td>0.2124</td>\n",
       "      <td>0.5014</td>\n",
       "      <td>0.5222</td>\n",
       "      <td>-0.3422</td>\n",
       "      <td>-0.5840</td>\n",
       "      <td>-0.7168</td>\n",
       "      <td>-0.6342</td>\n",
       "      <td>-0.8614</td>\n",
       "      <td>-0.8318</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.1112</td>\n",
       "      <td>-0.0476</td>\n",
       "      <td>-0.1746</td>\n",
       "      <td>0.0318</td>\n",
       "      <td>-0.0476</td>\n",
       "      <td>0.1112</td>\n",
       "      <td>0.2540</td>\n",
       "      <td>0.1588</td>\n",
       "      <td>-0.4762</td>\n",
       "      <td>'2'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.3808</td>\n",
       "      <td>-0.0096</td>\n",
       "      <td>0.2602</td>\n",
       "      <td>0.2554</td>\n",
       "      <td>-0.4290</td>\n",
       "      <td>-0.6746</td>\n",
       "      <td>-0.6868</td>\n",
       "      <td>-0.6650</td>\n",
       "      <td>-0.8410</td>\n",
       "      <td>-0.9614</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0504</td>\n",
       "      <td>-0.0360</td>\n",
       "      <td>-0.1224</td>\n",
       "      <td>0.1366</td>\n",
       "      <td>0.2950</td>\n",
       "      <td>0.0792</td>\n",
       "      <td>-0.0072</td>\n",
       "      <td>0.0936</td>\n",
       "      <td>-0.1510</td>\n",
       "      <td>'2'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.3412</td>\n",
       "      <td>0.0946</td>\n",
       "      <td>0.6082</td>\n",
       "      <td>0.6216</td>\n",
       "      <td>-0.1622</td>\n",
       "      <td>-0.3784</td>\n",
       "      <td>-0.4324</td>\n",
       "      <td>-0.4358</td>\n",
       "      <td>-0.4966</td>\n",
       "      <td>-0.5406</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1562</td>\n",
       "      <td>0.3124</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>-0.0938</td>\n",
       "      <td>0.1562</td>\n",
       "      <td>0.3124</td>\n",
       "      <td>0.3124</td>\n",
       "      <td>0.2188</td>\n",
       "      <td>-0.2500</td>\n",
       "      <td>'3'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 618 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       f1      f2      f3      f4      f5      f6      f7      f8      f9  \\\n",
       "0 -0.4394 -0.0930  0.1718  0.4620  0.6226  0.4704  0.3578  0.0478 -0.1184   \n",
       "1 -0.4348 -0.1198  0.2474  0.4036  0.5026  0.6328  0.4948  0.0338 -0.0520   \n",
       "2 -0.2330  0.2124  0.5014  0.5222 -0.3422 -0.5840 -0.7168 -0.6342 -0.8614   \n",
       "3 -0.3808 -0.0096  0.2602  0.2554 -0.4290 -0.6746 -0.6868 -0.6650 -0.8410   \n",
       "4 -0.3412  0.0946  0.6082  0.6216 -0.1622 -0.3784 -0.4324 -0.4358 -0.4966   \n",
       "\n",
       "      f10  ...    f609    f610    f611    f612    f613    f614    f615  \\\n",
       "0 -0.2310  ...  0.4102  0.2052  0.3846  0.3590  0.5898  0.3334  0.6410   \n",
       "1 -0.1302  ...  0.0000  0.2954  0.2046  0.4772  0.0454  0.2046  0.4318   \n",
       "2 -0.8318  ... -0.1112 -0.0476 -0.1746  0.0318 -0.0476  0.1112  0.2540   \n",
       "3 -0.9614  ... -0.0504 -0.0360 -0.1224  0.1366  0.2950  0.0792 -0.0072   \n",
       "4 -0.5406  ...  0.1562  0.3124  0.2500 -0.0938  0.1562  0.3124  0.3124   \n",
       "\n",
       "     f616    f617  class  \n",
       "0  0.5898 -0.4872    '1'  \n",
       "1  0.4546 -0.0910    '1'  \n",
       "2  0.1588 -0.4762    '2'  \n",
       "3  0.0936 -0.1510    '2'  \n",
       "4  0.2188 -0.2500    '3'  \n",
       "\n",
       "[5 rows x 618 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reading the first five row of the data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>f10</th>\n",
       "      <th>...</th>\n",
       "      <th>f609</th>\n",
       "      <th>f610</th>\n",
       "      <th>f611</th>\n",
       "      <th>f612</th>\n",
       "      <th>f613</th>\n",
       "      <th>f614</th>\n",
       "      <th>f615</th>\n",
       "      <th>f616</th>\n",
       "      <th>f617</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7792</th>\n",
       "      <td>-0.6842</td>\n",
       "      <td>-0.3280</td>\n",
       "      <td>-0.1984</td>\n",
       "      <td>0.2956</td>\n",
       "      <td>0.8786</td>\n",
       "      <td>0.8948</td>\n",
       "      <td>0.3118</td>\n",
       "      <td>0.1822</td>\n",
       "      <td>0.1012</td>\n",
       "      <td>0.1740</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7738</td>\n",
       "      <td>0.7738</td>\n",
       "      <td>0.7142</td>\n",
       "      <td>0.6428</td>\n",
       "      <td>0.5952</td>\n",
       "      <td>0.5714</td>\n",
       "      <td>0.3928</td>\n",
       "      <td>0.4286</td>\n",
       "      <td>0.2858</td>\n",
       "      <td>'24'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7793</th>\n",
       "      <td>-0.5912</td>\n",
       "      <td>-0.2420</td>\n",
       "      <td>0.8174</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.4642</td>\n",
       "      <td>0.6428</td>\n",
       "      <td>0.6944</td>\n",
       "      <td>0.3056</td>\n",
       "      <td>-0.3888</td>\n",
       "      <td>-0.6826</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1924</td>\n",
       "      <td>-0.1154</td>\n",
       "      <td>0.0192</td>\n",
       "      <td>0.2116</td>\n",
       "      <td>-0.0384</td>\n",
       "      <td>0.0192</td>\n",
       "      <td>-0.2308</td>\n",
       "      <td>-0.4230</td>\n",
       "      <td>-0.7116</td>\n",
       "      <td>'25'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7794</th>\n",
       "      <td>-0.6696</td>\n",
       "      <td>-0.3730</td>\n",
       "      <td>0.1584</td>\n",
       "      <td>0.8910</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9762</td>\n",
       "      <td>0.9762</td>\n",
       "      <td>0.7684</td>\n",
       "      <td>0.4106</td>\n",
       "      <td>0.0154</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0910</td>\n",
       "      <td>0.1818</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.1454</td>\n",
       "      <td>0.0182</td>\n",
       "      <td>-0.2910</td>\n",
       "      <td>0.0728</td>\n",
       "      <td>0.0728</td>\n",
       "      <td>-0.5818</td>\n",
       "      <td>'25'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7795</th>\n",
       "      <td>-0.5764</td>\n",
       "      <td>-0.1764</td>\n",
       "      <td>0.5106</td>\n",
       "      <td>0.3742</td>\n",
       "      <td>-0.1670</td>\n",
       "      <td>-0.5858</td>\n",
       "      <td>-0.7882</td>\n",
       "      <td>-0.7224</td>\n",
       "      <td>-0.6330</td>\n",
       "      <td>-0.8212</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4130</td>\n",
       "      <td>0.5870</td>\n",
       "      <td>0.4348</td>\n",
       "      <td>0.5652</td>\n",
       "      <td>0.3478</td>\n",
       "      <td>-0.0434</td>\n",
       "      <td>0.3044</td>\n",
       "      <td>-0.0434</td>\n",
       "      <td>-0.5000</td>\n",
       "      <td>'26'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7796</th>\n",
       "      <td>-0.6624</td>\n",
       "      <td>-0.3334</td>\n",
       "      <td>0.3666</td>\n",
       "      <td>0.4292</td>\n",
       "      <td>-0.2084</td>\n",
       "      <td>-0.5374</td>\n",
       "      <td>-0.4542</td>\n",
       "      <td>-0.6208</td>\n",
       "      <td>-0.6376</td>\n",
       "      <td>-0.5042</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2520</td>\n",
       "      <td>0.2846</td>\n",
       "      <td>0.4146</td>\n",
       "      <td>0.3170</td>\n",
       "      <td>0.2520</td>\n",
       "      <td>-0.0244</td>\n",
       "      <td>-0.0894</td>\n",
       "      <td>-0.1708</td>\n",
       "      <td>-0.3170</td>\n",
       "      <td>'26'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 618 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          f1      f2      f3      f4      f5      f6      f7      f8      f9  \\\n",
       "7792 -0.6842 -0.3280 -0.1984  0.2956  0.8786  0.8948  0.3118  0.1822  0.1012   \n",
       "7793 -0.5912 -0.2420  0.8174  1.0000  0.4642  0.6428  0.6944  0.3056 -0.3888   \n",
       "7794 -0.6696 -0.3730  0.1584  0.8910  1.0000  0.9762  0.9762  0.7684  0.4106   \n",
       "7795 -0.5764 -0.1764  0.5106  0.3742 -0.1670 -0.5858 -0.7882 -0.7224 -0.6330   \n",
       "7796 -0.6624 -0.3334  0.3666  0.4292 -0.2084 -0.5374 -0.4542 -0.6208 -0.6376   \n",
       "\n",
       "         f10  ...    f609    f610    f611    f612    f613    f614    f615  \\\n",
       "7792  0.1740  ...  0.7738  0.7738  0.7142  0.6428  0.5952  0.5714  0.3928   \n",
       "7793 -0.6826  ...  0.1924 -0.1154  0.0192  0.2116 -0.0384  0.0192 -0.2308   \n",
       "7794  0.0154  ...  0.0910  0.1818  0.2000  0.1454  0.0182 -0.2910  0.0728   \n",
       "7795 -0.8212  ...  0.4130  0.5870  0.4348  0.5652  0.3478 -0.0434  0.3044   \n",
       "7796 -0.5042  ...  0.2520  0.2846  0.4146  0.3170  0.2520 -0.0244 -0.0894   \n",
       "\n",
       "        f616    f617  class  \n",
       "7792  0.4286  0.2858   '24'  \n",
       "7793 -0.4230 -0.7116   '25'  \n",
       "7794  0.0728 -0.5818   '25'  \n",
       "7795 -0.0434 -0.5000   '26'  \n",
       "7796 -0.1708 -0.3170   '26'  \n",
       "\n",
       "[5 rows x 618 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reading the last five row of the data\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7797 entries, 0 to 7796\n",
      "Columns: 618 entries, f1 to class\n",
      "dtypes: float64(613), int64(4), object(1)\n",
      "memory usage: 36.8+ MB\n"
     ]
    }
   ],
   "source": [
    "#getting more info about the data\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f1       0\n",
       "f2       0\n",
       "f3       0\n",
       "f4       0\n",
       "f5       0\n",
       "        ..\n",
       "f614     0\n",
       "f615     0\n",
       "f616     0\n",
       "f617     0\n",
       "class    0\n",
       "Length: 618, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking for null value\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THIS TRUNCATE THE COLUMN AND ONE CAN'T SAY YET IF NULL VALUES ARE PRESENT.BELOW IS ANOTHER WAY TO CONFIRM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in data.columns:\n",
    "    if data[i].isnull().sum()!= 0:\n",
    "         print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ZERO OUTPUT SHOWS THE DATA IS NULL FREE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#checking for imbalance set in thr target column\n",
    "data[\"class\"].value_counts().plot(kind=\"bar\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THE DATA IS BALANCED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sepating the data into feature and and target column\n",
    "\n",
    "target=data.pop(\"class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7797, 617)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spliting the data into train and and test set\n",
    "feature_train,feature_test,target_train,target_test=train_test_split(data,target,random_state=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train data is 0.9988028048571918\n",
      "Accuracy on test data is 0.9041025641025641\n"
     ]
    }
   ],
   "source": [
    "#instantiating the model\n",
    "rf=RandomForestClassifier(random_state=42,n_estimators=10)\n",
    "\n",
    "#model fitting\n",
    "\n",
    "rf.fit(feature_train,target_train)\n",
    "\n",
    "#prediction on both train and test data\n",
    "\n",
    "pred_train=rf.predict(feature_train)\n",
    "pred_test=rf.predict(feature_test)\n",
    "\n",
    "#checking the accurary\n",
    "\n",
    "print(f\"Accuracy on train data is {accuracy_score(pred_train,target_train)}\")\n",
    "print(f\"Accuracy on test data is {accuracy_score(pred_test,target_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A GREAT RESULT BUT OVERFITTING OCCUR,HAND TUNING THE HYPERPARAMETER TO GET A BETTING RESULT AND TO PREVENT OVERFITTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train data is 1.0\n",
      "Accuracy on test data is 0.941025641025641\n"
     ]
    }
   ],
   "source": [
    "#instantiating the model and tuning the n_estimators\n",
    "rf=RandomForestClassifier(random_state=42,n_estimators=60)\n",
    "\n",
    "#model fitting\n",
    "\n",
    "rf.fit(feature_train,target_train)\n",
    "\n",
    "#prediction on both train and test data\n",
    "\n",
    "pred_train=rf.predict(feature_train)\n",
    "pred_test=rf.predict(feature_test)\n",
    "\n",
    "#checking the accurary\n",
    "\n",
    "print(f\"Accuracy on train data is {accuracy_score(pred_train,target_train)}\")\n",
    "print(f\"Accuracy on test data is {accuracy_score(pred_test,target_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train data is 0.9728065674704977\n",
      "Accuracy on test data is 0.9307692307692308\n"
     ]
    }
   ],
   "source": [
    "#instantiating the model and tuning the max_depth\n",
    "rf=RandomForestClassifier(\n",
    "    random_state=42,n_estimators=60,\n",
    "    max_depth=9)\n",
    "\n",
    "#model fitting\n",
    "\n",
    "rf.fit(feature_train,target_train)\n",
    "\n",
    "#prediction on both train and test data\n",
    "\n",
    "pred_train=rf.predict(feature_train)\n",
    "pred_test=rf.predict(feature_test)\n",
    "\n",
    "#checking the accurary\n",
    "\n",
    "print(f\"Accuracy on train data is {accuracy_score(pred_train,target_train)}\")\n",
    "print(f\"Accuracy on test data is {accuracy_score(pred_test,target_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train data is 0.9163673678809646\n",
      "Accuracy on test data is 0.8994871794871795\n"
     ]
    }
   ],
   "source": [
    "#instantiating the model and tuning the min_samples_leaf \n",
    "rf=RandomForestClassifier(\n",
    "    random_state=42,n_estimators=60,\n",
    "    max_depth=9,min_samples_leaf=50 )\n",
    "\n",
    "#model fitting\n",
    "\n",
    "rf.fit(feature_train,target_train)\n",
    "\n",
    "#prediction on both train and test data\n",
    "\n",
    "pred_train=rf.predict(feature_train)\n",
    "pred_test=rf.predict(feature_test)\n",
    "\n",
    "#checking the accurary\n",
    "\n",
    "print(f\"Accuracy on train data is {accuracy_score(pred_train,target_train)}\")\n",
    "print(f\"Accuracy on test data is {accuracy_score(pred_test,target_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train data is 0.9020010261672653\n",
      "Accuracy on test data is 0.8928205128205128\n"
     ]
    }
   ],
   "source": [
    "#instantiating the model and tuning the max_features\n",
    "rf=RandomForestClassifier(\n",
    "    random_state=42,n_estimators=60,\n",
    "    max_depth=9,min_samples_leaf=50,\n",
    "    max_features=0.25)\n",
    "\n",
    "#model fitting\n",
    "\n",
    "rf.fit(feature_train,target_train)\n",
    "\n",
    "#prediction on both train and test data\n",
    "\n",
    "pred_train=rf.predict(feature_train)\n",
    "pred_test=rf.predict(feature_test)\n",
    "\n",
    "#checking the accurary\n",
    "\n",
    "print(f\"Accuracy on train data is {accuracy_score(pred_train,target_train)}\")\n",
    "print(f\"Accuracy on test data is {accuracy_score(pred_test,target_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THIS A BETTER RESULT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         '1'       0.96      0.81      0.88        91\n",
      "        '10'       0.85      0.81      0.83        84\n",
      "        '11'       0.76      0.92      0.83        61\n",
      "        '12'       0.97      0.88      0.93        85\n",
      "        '13'       0.94      0.85      0.89        78\n",
      "        '14'       0.80      0.95      0.87        63\n",
      "        '15'       0.90      0.96      0.93        80\n",
      "        '16'       0.74      0.82      0.78        67\n",
      "        '17'       0.92      0.96      0.94        70\n",
      "        '18'       0.99      0.99      0.99        73\n",
      "        '19'       0.96      0.98      0.97        96\n",
      "         '2'       0.92      0.77      0.84        92\n",
      "        '20'       0.85      0.88      0.86        64\n",
      "        '21'       0.98      0.81      0.89       102\n",
      "        '22'       0.73      0.74      0.73        61\n",
      "        '23'       0.59      1.00      0.75        44\n",
      "        '24'       0.99      0.97      0.98        72\n",
      "        '25'       0.95      0.99      0.97        82\n",
      "        '26'       0.88      0.93      0.91        72\n",
      "         '3'       0.96      0.95      0.95        75\n",
      "         '4'       0.92      0.83      0.88        72\n",
      "         '5'       0.77      0.95      0.85        62\n",
      "         '6'       0.97      0.86      0.91        65\n",
      "         '7'       0.89      0.78      0.83        85\n",
      "         '8'       1.00      0.96      0.98        84\n",
      "         '9'       0.99      0.96      0.97        70\n",
      "\n",
      "    accuracy                           0.89      1950\n",
      "   macro avg       0.89      0.90      0.89      1950\n",
      "weighted avg       0.90      0.89      0.89      1950\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#checking confusion matrix and classification report\n",
    "\n",
    "print(classification_report(pred_test,target_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ALTHOUGH THE MODEL IS WORST IN CLASSIFYING SOME LETTER WELL,BUT STILL A BETTER MODEL CHECKING FROM THE RECALL VALUE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
